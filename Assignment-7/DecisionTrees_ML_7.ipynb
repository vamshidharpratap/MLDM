{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write group name, group members, matriculation numbers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following implementation is inspired by: http://gabrielelanaro.github.io/blog/2016/03/03/decision-trees.html\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "# x1 atmospheric pressure\n",
    "x1 = ['high', 'high', 'low', 'low', 'low', 'high']  \n",
    "# x2 is weather type\n",
    "x2 = ['partly cloudy', 'sunny', 'sunny', 'cloudy', 'cloudy', 'cloudy']  \n",
    "X = np.array([x1, x2]).T\n",
    "y = np.array([False, False, True, False, False, True]) # rain (True) and no-rain (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['high', 'partly cloudy'],\n",
       "       ['high', 'sunny'],\n",
       "       ['low', 'sunny'],\n",
       "       ['low', 'cloudy'],\n",
       "       ['low', 'cloudy'],\n",
       "       ['high', 'cloudy']], dtype='<U13')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False, False,  True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_1 = cloudy:\n",
      " x_0 = high: True\n",
      " x_0 = low: False\n",
      "x_1 = partly cloudy: False\n",
      "x_1 = sunny:\n",
      " x_0 = high: False\n",
      " x_0 = low: True\n"
     ]
    }
   ],
   "source": [
    "# Splitting a set\n",
    "# Input is an array of feature observations and output is a dictionary with \"unique feature value\" as key and indices as value\n",
    "def partition(a):\n",
    "    return {c: (a==c).nonzero()[0] for c in np.unique(a)}\n",
    "\n",
    "# Picking which attribute to split\n",
    "# Calculate entropy of a list\n",
    "def entropy(s):\n",
    "    res = 0\n",
    "    val, counts = np.unique(s, return_counts=True)\n",
    "    freqs = counts.astype('float')/len(s)\n",
    "    for p in freqs:\n",
    "        if p != 0.0:\n",
    "            res -= p * np.log2(p)\n",
    "    return res\n",
    "\n",
    "# Calculate decrease in impurity (information gains)\n",
    "# \n",
    "def mutual_information(y, x):\n",
    "    \n",
    "    # Calculate entropy of observation classes\n",
    "    res = entropy(y)\n",
    "\n",
    "    # We partition x, according to attribute values x_i\n",
    "    val, counts = np.unique(x, return_counts=True)\n",
    "    freqs = counts.astype('float')/len(x)\n",
    "\n",
    "    # We calculate a weighted average of the entropy and subtract it from parent entropy\n",
    "    for p, v in zip(freqs, val):\n",
    "        res -= p * entropy(y[x == v])\n",
    "\n",
    "    return res\n",
    "\n",
    "# Checks for pureness of elements in a list\n",
    "def is_pure(s):\n",
    "    return len(set(s)) == 1\n",
    "\n",
    "# Helper function to print decision tree\n",
    "def print_tree(d, depth = 0):\n",
    "    for key, value in d.items():\n",
    "        for i in range(depth):\n",
    "                print(' ', end='')\n",
    "        if type(value) is dict:\n",
    "            print(key, end=':\\n')\n",
    "            print_tree(value, depth + 1)\n",
    "        else:\n",
    "            print(key, end=': ')\n",
    "            print(value)\n",
    "            \n",
    "# Get the most common element of an array\n",
    "def most_common(a):\n",
    "    (values,counts) = np.unique(a,return_counts=True)\n",
    "    ind=np.argmax(counts)\n",
    "    return values[ind]\n",
    "\n",
    "# Recursive split of observations\n",
    "def recursive_split(x, y):\n",
    "    \n",
    "    # If set to be split is pure or empty, return it as leaf\n",
    "    if is_pure(y) or len(y) == 0:\n",
    "        return most_common(y)\n",
    "\n",
    "    # Calculate decrease in impurity (information gain) and split attribute with maximum gain\n",
    "    gain = np.array([mutual_information(y, x_attr) for x_attr in x.T])\n",
    "    selected_attr = np.argmax(gain)\n",
    "\n",
    "    # Sufficiently pure, return it as leaf\n",
    "    if np.all(gain < 1e-6):\n",
    "        return most_common(y)\n",
    "\n",
    "    # Split using the selected attribute\n",
    "    sets = partition(x[:, selected_attr])\n",
    "\n",
    "    # Perform recursive splits and collect results\n",
    "    res = {}\n",
    "    for key, value in sets.items():\n",
    "        y_subset = y.take(value, axis=0)\n",
    "        x_subset = x.take(value, axis=0)\n",
    "        res[\"x_%d = %s\" % (selected_attr, key)] = recursive_split(x_subset, y_subset)\n",
    "\n",
    "    return res\n",
    "\n",
    "# Perform algorithm on the example dataset to create a decision tree\n",
    "d = recursive_split(X, y)\n",
    "print_tree(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataset (which shall be classified by the above generated decision tree)\n",
    "x1 = ['high', 'low', 'low', 'high', 'low', 'high', 'high', 'low', 'low', 'high', 'low', 'low']\n",
    "x2 = ['sunny', 'sunny', 'cloudy', 'cloudy', 'partly cloudy', 'cloudy', 'partly cloudy', 'cloudy', 'sunny', 'cloudy', 'cloudy', 'partly cloudy']\n",
    "X = np.array([x1, x2]).T\n",
    "y = np.array([False, True, True, False, False, True, False, True, True, False, True, True]) # ground-truth of classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# work here on the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rains(test_feature,dTree):\n",
    "    \"\"\"\n",
    "    This function will predict the class label for the given feature sample\n",
    "    :param test_feature: Feature sample as an input paramter for which we need to predict\n",
    "    :param dTree :       Decsion tree which has been already trained on different data\n",
    "    \n",
    "    returns : class label 'Y' for the given feature\n",
    "    \"\"\"\n",
    "    \n",
    "    for attribute in dTree.keys():\n",
    "        \n",
    "        if test_feature[1] in attribute:\n",
    "            label = dTree[attribute]\n",
    "            #checking if it is leaf node \n",
    "            if isinstance(label,np.bool_):   \n",
    "                test_label = label\n",
    "            #If it has child nodes, iterating over the childnodes        \n",
    "            elif isinstance(label,dict):\n",
    "                if test_feature[0] in list(label.keys())[0]:\n",
    "                    test_label = list(label.values())[0]\n",
    "                else:\n",
    "                    test_label = list(label.values())[1]\n",
    "                  \n",
    "    return test_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification result for the given input features is :\n",
      "[False, True, False, False, False, False, False, False, True, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "#Iterating over the features \n",
    "y_labels = [predict_rains(test,d) for test in X]\n",
    "print(\"Classification result for the given input features is :\")\n",
    "print(y_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the decision tree data structure stored in the variable d. Which python data types are used in which combination? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree 'd' has been constructed by making use of dictionary data structre. Here the keys represents the feature type \"wheather type\". If the corresponding feature in training data has same class labels (if it is pure node) then the corresponding value will be result a numpy boolean value which represents whether rain falls are not ( Y value to be predicted). Other wise the value will be a sub tree which is constructed on feature atmospheric pressure. In the corresponding sub tree which is also a dictionary where keys represent feature atmospheric pressure and values represent the result i.e., a numpy boolean value where True represents it rains and False represents it wont rains.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
